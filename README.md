# Text Diffusion Model Trainer with Tkinter GUI

This project demonstrates the training of a simplified Denoising Diffusion Probabilistic Model (DDPM) for text generation. It features a real-time training dashboard built with Python's Tkinter library to visualize the process.

The model is trained on the "roneneldan/TinyStories" dataset and learns to generate short, coherent sentences by reversing a diffusion (noise-adding) process. The GUI provides live updates on training loss, generated text samples, and overall progress.

![Application Screenshot](./.assets/screenshot.png)
*(Note: A placeholder for a screenshot of the running application. You can add one yourself after running the code.)*

## Features

-   **Dataset**: Downloads and uses the "roneneldan/TinyStories" dataset from Hugging Face `datasets`.
-   **Custom Tokenizer**: Trains a Byte-Pair Encoding (BPE) tokenizer from scratch on the dataset using `tokenizers`.
-   **Diffusion Model**: Implements a simple Transformer Encoder-based model in PyTorch to act as the denoiser.
-   **Live Training GUI**:
    -   Built with Tkinter for a native desktop experience.
    -   Displays live statistics: Current Epoch, Step, and Loss.
    -   Features a Matplotlib plot, embedded in the GUI, showing the training loss curve as it updates.
    -   Shows sample sentences generated by the model at periodic intervals, illustrating its learning progress.
-   **Multithreaded**: The entire training process runs in a background thread to ensure the GUI remains responsive.

## How to Run

### 1. Prerequisites

-   Python 3.8 or higher.
-   `git` for cloning the repository.

### 2. Setup Environment

First, clone the repository to your local machine:
```bash
git clone <repository-url>
cd <repository-directory>
```
It is recommended to create a virtual environment to manage dependencies:
```bash
python -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
```

### 3. Install Dependencies

Install all the required Python packages using the `requirements.txt` file:
```bash
pip install -r requirements.txt
```

### 4. Run the Application

Execute the `main.py` script to launch the GUI and start the training process:
```bash
python main.py
```

---

### **⚠️ Important Note for First Run**

The **first time you run the application**, it will perform a one-time setup that can be slow:

1.  **Download Dataset**: It will download a portion of the "TinyStories" dataset. This can take several minutes depending on your internet connection.
2.  **Train Tokenizer**: It will train a BPE tokenizer from scratch on a sample of the dataset.

Subsequent runs will be much faster as they will use the cached dataset and the saved tokenizer file (`bpe_tokenizer.json`).

---

## GUI Layout

The application window is divided into three main sections:

1.  **Live Statistics (Top)**: Displays the current `Epoch`, `Step`, `Loss`, and a `Status` message indicating the current state of the trainer (e.g., "Initializing", "Training", "Generating sample...").
2.  **Training Loss Plot (Left)**: A Matplotlib graph that plots the training loss against the number of steps, updating in real-time.
3.  **Generated Sample (Right)**: A text box that periodically displays a sentence generated by the model, allowing you to see its ability to form coherent text improve over time.

## Project Structure

The project is organized into several Python modules for clarity and maintainability:

-   `main.py`: The main entry point. Sets up the Tkinter GUI and starts the training thread.
-   `trainer.py`: Contains the `TrainerThread` class, which handles all core logic: the training loop, the diffusion process (forward and reverse), and sampling.
-   `diffusion_model.py`: Defines the PyTorch `TextDiffusionModel` architecture, which is based on a Transformer Encoder.
-   `data_loader.py`: Manages all data-related tasks, including downloading the dataset, training/loading the tokenizer, and creating the PyTorch `DataLoader`.
-   `config.py`: A centralized file for all hyperparameters and configuration settings (e.g., learning rate, batch size, embedding dimensions, etc.).
-   `requirements.txt`: Lists all project dependencies.
